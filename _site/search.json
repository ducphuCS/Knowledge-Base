[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/2021/SPAC.html",
    "href": "posts/2021/SPAC.html",
    "title": "SPAC",
    "section": "",
    "text": "Original Link\nCác lựa chọn để huy động vốn - đầu tư vốn trực tiếp vào công ty - phát hành cổ phiếu mới - sát nhập với công ty mua lại mục đích đặc biệt (SPAC) - các giao dịch khác\n\nCông ty mua lại có mục đích đặc biệt Special Purpose Acquisition Company - SPAC\nlà một công cụ giúp các công ty chưa niêm yết thực hiện quá trình niêm yết trên thị trường chứng khoán thông qua sát nhập ngược.\nNiêm yết chứng khoán tại nước ngoài đòi hỏi những yêu cầu khắt khe và nhiều sàn giao dịch chứng khoán còn chưa công nhận thị trường Việt Nam đạt chuẩn cho đăng ký hoạt động đối với các doanh nghiệp muốn niêm yết. Vì vậy, sát nhập ngược (reverse merger) với SPACs - tức là các công ty tư nhân sẽ bị mua lại bởi các SPACs và trở thành công ty đại chúng, có thể coi là một trong những phương pháp tốt nhất giúp các doanh nghiệp Việt Nam có thể niêm yết cổ phiếu tại nước ngoài.\n\nKhái niệm\nCông ty mua lại có mục đích đặc biệt (SPACs) là những công ty được thành lập bởi một nhóm nhỏ các nhà đầu tư sành sỏi hoặc các chuyên gia đầu ngành (gọi chung là các nhà sáng lập SPACs) và tiến hành huy động vốn thông qua phát hành lần đầu ra công chúng (IPO) nhằm mục tiêu duy nhất là thu mua hoặc sát nhập với một công ty chưa niêm yết đang hoạt động.\nNhững nhà sáng lập SPACs, còn được gọi là những nhà tài trợ SPAC (SPAC Sponsors), hoặc nhà quản trị SPAC (SPAC Managers) hoặc nhà bảo trợ SPAC (SPAC Promoters), thường được chia thành 4 nhóm: - Nhà điều hành kinh doanh giỏi Accomplished Operating Executives: những nhà điều hành kinh doanh thành công muốn theo đuổi các thương vụ mua lại.SPAC là cơ hội đem lại cho họ sự độc lập cũng như nguồn lợi tài chính tiềm năng và lớn hơn nhiều lần so với vị trí điều hành hoạt động như tại 1 quỹ đầu tư vốn tư nhân Private Equity Funds.\nNhà sáng lập không có nguồn vốn Unfunded Financial Sponsors: SPACs cũng thường được thành lập bởi các nhà thương lượng/đàm phán với quan hệ rộng rãi. Họ không trực tiếp tài trợ tài chính nhưng sẽ tìm kiếm các nhà đầu tư tiềm năng để thương lượng và cùng thành lập SPACs từ nguồn vốn tài chính của những nhà đầu tư kêu gọi được.\nNhà quản lý tài sản thay thế Alternative Asset Managers: Các quản lý tài sản thay thế đầu tư thành lập SPACs như 1 công cụ để tiến hành các giao dịch kiểm soát và nắm bắt những cơ hội đầu tư thay thế, điển hình là các quỹ đầu cơ và quỹ đầu tư vốn tư nhân. Nếu như quỹ đầu cơ bình thường chỉ tập trung vào các khoản đầu tư có tính thanh khoản cao thì việc thành lập SPACs giúp các quỹ thu mua được các công ty chưa đại chúng, thay vì đầu tư trực tiếp lên tài sản vốn của những công ty này. Đây được coi là phương pháp đầu tư giảm thiểu rủi ro cho các nhà đầu tư vào quỹ.\nDoanh nghiệp Corporates: SPACs là cơ hội cho các công ty đại chúng mở rộng hoạt động kinh doanh. Trong trường hợp công ty bắt buộc phải phát hành cổ phiếu để kích thích giá mua khi thị trường đang sụt giảm liên tục thì việc tài trợ thành lập 1 SPAC chính là cách huy động vốn cho công ty và có khả năng hoàn thành kế hoạch thu mua công ty khác mà tránh được sự sụt giảm giá trị bởi công ty sẽ nhận được 20% số cổ phiếu của SPAC sau khi IPO. Bên cạnh đó, các doanh nghiệp có thể mở rộng ngành nghề kinh doanh thông qua SPAC.\n\n\nCách thức hoạt động\nNhững người thành lập SPACs phải nói rõ ràng rằng chưa xem xét bất kỳ thương vụ mua bán nào và không có bất kỳ cuộc thảo luận nào với ai về những giao dịch tiềm năng này. SPACs huy động vốn thông qua IPO theo cách truyền thống có bảo đảm. Một khi SPACs nhận tiền từ IPO thì công ty sẽ bắt đầu quá trình tìm kiếm các đối tượng mục tiêu để thực hiện mua bán hoặc sáp nhập. Khi tìm được công ty mục tiêu, SPAC sẽ thông báo giao dịch này ra thị trường và hoàn thiện thuyết trình theo yêu cầu của SEC nhằm thu hút sự đồng thuận của các cổ đông. SPAC sẽ kết thúc được giao dịch khi công ty nhận được sự đồng ý của các cổ đông. Sau đó, công ty mục tiêu sẽ được sáp nhập và SPAC và trở thành một công ty đại chúng."
  },
  {
    "objectID": "posts/2021/TOPSIS.html",
    "href": "posts/2021/TOPSIS.html",
    "title": "TOPSIS",
    "section": "",
    "text": "(Origin){https://en.m.wikipedia.org/wiki/TOPSIS}\nThe Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) is a multi-criteria decision analysis method. TOPSIS is based on the concept that the chosen alternative should have the shortest geometric distance from the positive ideal solution (PIS) and the longest geometric distance from the negative ideal solution (NIS)\n\nDescription It is a method of compensatory aggregation that compares a set of alternatives by identifying weights for each criterion, normalizing scores for each criterion and calculating the geometric distance between each alternative and the ideal alternative, which is the best score in each"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/2021/Deep-Learning.html",
    "href": "posts/2021/Deep-Learning.html",
    "title": "Deep Learning",
    "section": "",
    "text": "AI is the new Electricity\nElectricity had once transformed countless industries: transportation, manufacturing, healthcare, communications, and more\nAI will now bring about an equally big transformation.\n\nWhat you’ll learn Courses: 1. Neural Networks and Deep Learning: Build NN and train data 2. Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization 3. Structuring your Machine Learning project: best practices for this topic 4. Convolutional Neural Networks 5. Natural Language Processing: Building sequence models (RNN, LSTM)\n\n\n\n\n\n\n\n\nWhat is Neural Networks?\n\n\n\n\nExample 1\n\n\na larger neural network is formed by taking many of single neural networks and stacking them together.\n\n\n\nExample 2\n\n\n\ninput x will be (size, #bedrooms, zip code, wealth).\noutput y is price\nwhile family size, school quality,… are called hidden units.\n\nRemark: - given enough training examples with both x and y, NN are remarkably good at figuring out functions that accurately map from x to y. - every input layer feature is interconnected with every hidden layer feature.\n\nSupervised Learning with Neural networks In supervised learning, you have some input x, and you want to learn a function mapping to some output y.\n\n\n\n\nSupervised Learning\n\n\nIt turns out that different neural networks are useful for different applications\nFor examples, - Real Estate, Online Advertising: universally standard NN - Image applications: CNN - Sequence data (Audio): RNN - Language: more complex versions of RNN - Autonomous driving: Custom/Hybrid NN\nbased on the characteristics of data\nStructured and Unstructured Data: - Structured: has well-defined meaning - Unstructured: refers to audio, images, texts. One of the most exciting things about the rise of the NN is that, computers are now much better at interpreting unstructured data compared to just a few years ago.\nBut it turns out that a lot of short term economic value that NN are creating are also been on structured data, such as much better advertising and recommendation systems.\nSummary: NN has transformed supervised learning and are creating tremendous economic values.\n\nWhy is DL taking off?\n\nMain drivers behind the rise of DL Scales drives DL progress: - Data - Computation - Algorithms\nWith small training sets, performance depends much more on your skill at engine features and other details of the algorithm. With large training sets, more consistently see the large NN dominating the other approaches.\n\n\n\nDrivers of NN\n\n\nOne of the huge breakthroughs in NN has been switching from a sigmoid function to a ReLU function.\nBecause one of the problems of using sigmoid function in machine learning is that these regions where the slope of the function gradient is nearly zero and so learning becomes really slow, whereas by changing the activation function, the gradient is equal to one for all positive values of input and so the gradient is much less likely to shrink to zero.\nSwitching to ReLU has caused the gradient descent work much faster.\nCareer Advice: Geoffrey Hinton - Read the literature but don’t read too much of it. - Never stop programming.\n\n\n\n\n\n\nPurpose - Some important technique when implementing neural network. - Computation of neural network: forward propagation step and backward propagation step - Why the computation, the learning an neural network can be organized in this forward and backward propagation.\n\nBinary Classification:\n\nWe need to convert the image into feature vector X, i.e. for 64*64 images, x has the dimension of 64 x 64 x 3 = 12288\nand predict whether the corresponding label y is 1 or 0,\nNotation: - A single training example is represented by a pair (x, y) - m training examples - M_train and M_set for number of training and testing examples.\n\n\n\nNotation\n\n\n\nLogistic Regression A learning algorithm that you use when the output labels y in a supervised learning problem is either 1 or 0.\n\n\n\n\nLog Regression"
  },
  {
    "objectID": "posts/2021/Deep-Learning.html#welcome",
    "href": "posts/2021/Deep-Learning.html#welcome",
    "title": "Deep Learning",
    "section": "",
    "text": "AI is the new Electricity\nElectricity had once transformed countless industries: transportation, manufacturing, healthcare, communications, and more\nAI will now bring about an equally big transformation.\n\nWhat you’ll learn Courses: 1. Neural Networks and Deep Learning: Build NN and train data 2. Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization 3. Structuring your Machine Learning project: best practices for this topic 4. Convolutional Neural Networks 5. Natural Language Processing: Building sequence models (RNN, LSTM)"
  },
  {
    "objectID": "posts/2021/Deep-Learning.html#neural-networks-and-deep-learning",
    "href": "posts/2021/Deep-Learning.html#neural-networks-and-deep-learning",
    "title": "Deep Learning",
    "section": "",
    "text": "What is Neural Networks?\n\n\n\n\nExample 1\n\n\na larger neural network is formed by taking many of single neural networks and stacking them together.\n\n\n\nExample 2\n\n\n\ninput x will be (size, #bedrooms, zip code, wealth).\noutput y is price\nwhile family size, school quality,… are called hidden units.\n\nRemark: - given enough training examples with both x and y, NN are remarkably good at figuring out functions that accurately map from x to y. - every input layer feature is interconnected with every hidden layer feature.\n\nSupervised Learning with Neural networks In supervised learning, you have some input x, and you want to learn a function mapping to some output y.\n\n\n\n\nSupervised Learning\n\n\nIt turns out that different neural networks are useful for different applications\nFor examples, - Real Estate, Online Advertising: universally standard NN - Image applications: CNN - Sequence data (Audio): RNN - Language: more complex versions of RNN - Autonomous driving: Custom/Hybrid NN\nbased on the characteristics of data\nStructured and Unstructured Data: - Structured: has well-defined meaning - Unstructured: refers to audio, images, texts. One of the most exciting things about the rise of the NN is that, computers are now much better at interpreting unstructured data compared to just a few years ago.\nBut it turns out that a lot of short term economic value that NN are creating are also been on structured data, such as much better advertising and recommendation systems.\nSummary: NN has transformed supervised learning and are creating tremendous economic values.\n\nWhy is DL taking off?\n\nMain drivers behind the rise of DL Scales drives DL progress: - Data - Computation - Algorithms\nWith small training sets, performance depends much more on your skill at engine features and other details of the algorithm. With large training sets, more consistently see the large NN dominating the other approaches.\n\n\n\nDrivers of NN\n\n\nOne of the huge breakthroughs in NN has been switching from a sigmoid function to a ReLU function.\nBecause one of the problems of using sigmoid function in machine learning is that these regions where the slope of the function gradient is nearly zero and so learning becomes really slow, whereas by changing the activation function, the gradient is equal to one for all positive values of input and so the gradient is much less likely to shrink to zero.\nSwitching to ReLU has caused the gradient descent work much faster.\nCareer Advice: Geoffrey Hinton - Read the literature but don’t read too much of it. - Never stop programming.\n\n\n\n\n\n\nPurpose - Some important technique when implementing neural network. - Computation of neural network: forward propagation step and backward propagation step - Why the computation, the learning an neural network can be organized in this forward and backward propagation.\n\nBinary Classification:\n\nWe need to convert the image into feature vector X, i.e. for 64*64 images, x has the dimension of 64 x 64 x 3 = 12288\nand predict whether the corresponding label y is 1 or 0,\nNotation: - A single training example is represented by a pair (x, y) - m training examples - M_train and M_set for number of training and testing examples.\n\n\n\nNotation\n\n\n\nLogistic Regression A learning algorithm that you use when the output labels y in a supervised learning problem is either 1 or 0.\n\n\n\n\nLog Regression"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Knowledge-Base",
    "section": "",
    "text": "Welcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nJul 15, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\n\n\n\n\n\n\nTOPSIS\n\n\n\n\n\n\nother\n\n\n\n\n\n\n\n\n\nMay 7, 2021\n\n\nPhu Nguyen-Duc\n\n\n\n\n\n\n\n\n\n\n\n\nDeep Learning\n\n\n\n\n\n\nmachine-learning\n\n\ndeep-learning\n\n\n\n\n\n\n\n\n\nJan 1, 2021\n\n\nPhu Nguyen-Duc\n\n\n\n\n\n\n\n\n\n\n\n\nSPAC\n\n\n\n\n\n\nfinance\n\n\n\n\n\n\n\n\n\nJan 1, 2021\n\n\nPhu Nguyen-Duc\n\n\n\n\n\n\nNo matching items"
  }
]